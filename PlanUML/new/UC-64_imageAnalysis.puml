@startuml Get AI Assistant Response (Image Analysis)

actor User as "User"
boundary "GeminiChat" as View #lightblue
participant ":callGeminiAPI" as APIHandler #lightblue
participant ":GoogleGenerativeAI" as SDK #lightgreen
database "Gemini AI Server" as GeminiServer #yellow

Group AI Assistant Chat (Image Analysis)
    User -> View: 1. Uploads image (click or drag-drop)
    activate User
    activate View

    View -> View: 2. handleImageUpload()
    activate View
    deactivate View

    View -> View: 3. Read image as Base64 (FileReader)
    activate View
    deactivate View

    User -> View: 4. Enters question (text)
    User -> View: 5. Clicks Send

    View -> APIHandler: 6. callGeminiAPI(input, selectedImage)
    activate APIHandler

    APIHandler -> SDK: 7. new GoogleGenerativeAI(API_KEY)
    activate SDK

    SDK --> APIHandler: 8. Return genAI instance
    deactivate SDK

    APIHandler -> SDK: 9. genAI.getGenerativeModel({ model: VITE_MODEL })
    activate SDK
    SDK --> APIHandler: 10. Return model instance
    deactivate SDK

    APIHandler -> APIHandler: 11. Prepare multi-modal content (PROMPT + text + image data)
    activate APIHandler
    deactivate APIHandler

    APIHandler -> GeminiServer: 13. model.generateContent(content)
    activate GeminiServer

    GeminiServer --> APIHandler: 14. Return message
    deactivate GeminiServer
    
    opt API Error
        APIHandler --> View: 14.1. Return error string ("Sorry, I've been a bit busy...")
        View --> User: 14.2. Display error message
    end
    
    APIHandler --> View: 15. Return response
    deactivate APIHandler
    
    View --> User: 16. Display full response
    deactivate User
    deactivate View

end
@enduml